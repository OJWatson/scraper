% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/url-pdf-text-pull.R
\name{URL_PDF_Text_Pull}
\alias{URL_PDF_Text_Pull}
\title{PDF scrape text from a list of pdf urls generated from a scrape of href urls given minimal css}
\usage{

  URL_PDF_Text_Pull(url = "http://www.who.int/globalchange/resources/country-profiles/en/",
  css = ".a_z a", string = "Population (2013)", pdf.dir.dump,
  col.names = c("Number", "Size"), search.length = 200, words = c(2, 3))
}
\arguments{
\item{url}{Url containing links to pdfs}

\item{css}{Minimal css selector for links in url}

\item{string}{String which is to eb matched from pdf.}

\item{pdf.dir.dump}{Directory path where pdfs are downloaded to}

\item{col.names}{vector of length 2 for data frame result names}

\item{search.length}{Integer giving the length of the pdf text to search after the occurence of string}

\item{words}{Vector of integer determining which words to store from the search length. N.B. function will fail if the
number of words is greater than the actual number of words that appear after the search string search length}
}
\value{
list of dataframes of scraped information
}
\description{
\code{URL_PDF_Text_Pull} takes a url and scrapes your wanted urls from a minimum css selector. These urls are
pdfs which are then downloaded and text scraped for 2 words that appear after a provided string.
}

